from sentence_transformers import SentenceTransformer, util
import spacy
import os

# Forzar uso de CPU si hay incompatibilidad CUDA
os.environ['CUDA_VISIBLE_DEVICES'] = ''

nlp = spacy.load("es_core_news_sm")

model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", device='cpu')

GENERICOS = {
    "animal", "cosa", "ser", "objeto", "elemento", "lugar",
    "imagen", "foto", "fotografÃ­a", "dibujo", "figura", "ilustraciÃ³n", "grÃ¡fico"
}

# CategorÃ­as genÃ©ricas que deben ignorarse para buscar el sujeto especÃ­fico
CATEGORIAS_GENERICAS = {
    "accidente", "geogrÃ¡fico", "derecho", "evento", "edificio", "histÃ³rico",
    "sistema", "actividad", "responsabilidad", "tarea", "ciclo", "vida", 
    "familiar", "familia", "digno", "adecuado"
}


def similitud_semantica(texto1: str, texto2: str) -> float:
    """
    Calcula la similitud semÃ¡ntica entre dos textos usando Sentence Transformers.
    Devuelve un valor aproximado entre 0 y 1.
    """
    emb1 = model.encode(texto1, convert_to_tensor=True, device='cpu')
    emb2 = model.encode(texto2, convert_to_tensor=True, device='cpu')
    return util.cos_sim(emb1, emb2).item()


def obtener_sujeto(frase: str):
    """
    Obtiene el sujeto SEMÃNTICO de la frase:
    el sustantivo importante (burro, aviÃ³n, rÃ­o, montaÃ±a, sistema circulatorio, etc.).
    Captura sustantivos compuestos completos (noun chunks).
    No se usa el sujeto gramatical (yo, tÃº, Ã©l).
    """
    doc = nlp(frase)
    candidatos = []
    
    print(f"\nðŸ” DEBUG - Analizando frase: '{frase}'")

    # Primero intentar con noun chunks completos (captura "sistema circulatorio", "aparato digestivo", etc.)
    for chunk in doc.noun_chunks:
        print(f"  ðŸ“¦ Chunk detectado: '{chunk.text}' | root: {chunk.root.text} | root.pos_: {chunk.root.pos_}")
        
        # Filtrar palabras genÃ©ricas del chunk y limitar a las primeras palabras importantes
        palabras_importantes = []
        for token in chunk:
            print(f"    - Token: '{token.text}' | lemma: '{token.lemma_}' | pos: {token.pos_} | is_stop: {token.is_stop}")
            
            # Detener si encontramos preposiciÃ³n, verbo o puntuaciÃ³n (marca fin del sujeto)
            if token.pos_ in ("ADP", "VERB", "PUNCT") or token.text in (":", ",", "en", "de", "con", "para"):
                print(f"    â›” Deteniendo en: '{token.text}' (pos: {token.pos_})")
                break
            
            if token.pos_ in ("NOUN", "PROPN", "ADJ") and not token.is_stop:
                lema = token.lemma_.lower()
                # Saltar tanto genÃ©ricos como categorÃ­as generales
                if lema not in GENERICOS and lema not in CATEGORIAS_GENERICAS:
                    palabras_importantes.append(lema)
                    # Limitar a mÃ¡ximo 2 palabras para sustantivos compuestos simples
                    if len(palabras_importantes) >= 2:
                        break
        
        if palabras_importantes:
            # Unir palabras importantes del chunk (ej: "sistema circulatorio")
            sujeto_compuesto = " ".join(palabras_importantes)
            print(f"  âœ… Candidato encontrado: '{sujeto_compuesto}'")
            candidatos.append((chunk.start, sujeto_compuesto))

    # Si no encontramos chunks, buscar sustantivos individuales
    if not candidatos:
        print("  âš ï¸ No se encontraron chunks, buscando sustantivos individuales...")
        for token in doc:
            if token.pos_ in ("NOUN", "PROPN") and not token.is_stop:
                lema = token.lemma_.lower()
                if lema not in GENERICOS and lema not in CATEGORIAS_GENERICAS:
                    candidatos.append((token.i, lema))

    if not candidatos:
        print("  âŒ No se encontraron candidatos")
        return None

    # Retornar el primer candidato (mÃ¡s a la izquierda en la frase)
    candidatos.sort(key=lambda x: x[0])
    resultado = candidatos[0][1]
    print(f"  ðŸŽ¯ Sujeto extraÃ­do: '{resultado}'\n")
    return resultado


def evaluar_respuesta(texto_modelo: str, texto_nino: str, umbral: float = 0.6):
    """
    EvalÃºa la respuesta del niÃ±o comparÃ¡ndola con el texto del modelo.

    Flujo:
      1. Se obtiene el sujeto SEMÃNTICO de cada texto.
      2. Si los sujetos son distintos (o falta alguno), la respuesta es incorrecta.
      3. Si los sujetos son iguales, se calcula la similitud semÃ¡ntica.
      4. Si la similitud >= umbral, se considera correcta.
    """

    sujeto_modelo = obtener_sujeto(texto_modelo)
    sujeto_nino = obtener_sujeto(texto_nino)

    sujeto_igual = (
        sujeto_modelo is not None
        and sujeto_nino is not None
        and sujeto_modelo == sujeto_nino
    )

    if not sujeto_igual:
        return {
            "texto_modelo": texto_modelo,
            "texto_nino": texto_nino,
            "sujeto_modelo": sujeto_modelo,
            "sujeto_nino": sujeto_nino,
            "sujeto_igual": False,
            "similitud": 0.0,
            "umbral": umbral,
            "es_correcta": False,
        }

    sim = similitud_semantica(texto_modelo, texto_nino)
    
    # Bonus de 0.15 cuando los sujetos coinciden
    sim_con_bonus = min(sim + 0.15, 1.0)
    es_correcta = sim_con_bonus >= umbral

    return {
        "texto_modelo": texto_modelo,
        "texto_nino": texto_nino,
        "sujeto_modelo": sujeto_modelo,
        "sujeto_nino": sujeto_nino,
        "sujeto_igual": True,
        "similitud": sim_con_bonus,
        "umbral": umbral,
        "es_correcta": es_correcta,
    }
